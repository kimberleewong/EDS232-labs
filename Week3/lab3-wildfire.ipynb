{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d41e7de-5f0c-4baf-a37f-ec5dbe4f7428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492775e-957c-40b4-b64f-5de93dbea5e1",
   "metadata": {},
   "source": [
    "# Lab 4: Fire and Tree Mortality\n",
    "\n",
    "# About the data\n",
    "Wildfires are increasingly frequent and severe due to climate change. Predicting tree mortality following a wildfire is critical for forest management, ecosystem recovery, and carbon sequestration planning. In this lab, we will build a logistic regression model to predict the probability of tree mortality one year after a wildfire\n",
    "\n",
    "The database we'll be working with today includes observations of individual trees involved in prescribed fires and wildfires occurring over 35 years, from 1981 to 2016. It is drawn from a fire and tree mortality database from the US Forest Service (see data description for the full database here: [link](https://www.nature.com/articles/s41597-020-0522-7#Sec10)).\n",
    "\n",
    "The target variable we'll use is `yr1status`, which is a binary variable (0=alive, 1=dead).  This tells us if a tree has died one year after a fire event.\n",
    "\n",
    "The features we'll use are `YrFireName`, `Times_burned`, `Species`, `Genus_species`,\n",
    "    `DBH_cm`, `HT_m`, `CR_pre`, and `CR_post`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c5ce6-eb43-4544-8b88-c306a7618c85",
   "metadata": {},
   "source": [
    "## Step 1: Check the metadata\n",
    "\n",
    "Look at the metadata and provide a description on what each variable represents in the Description column below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b239ac-123f-4458-bf2c-fc46dcf5cc0a",
   "metadata": {},
   "source": [
    "| Feature                     | Description                                                                                   |\n",
    "|-----------------------------|-----------------------------------------------------------------------------------------------| \n",
    "| yr1status                   | binary status if tree has died one year after fire event\n",
    "| YrFireName                  | year and name of fire                           \n",
    "| Times_burned                | number of times tree burned                                             \n",
    "| Species                     | symbol for species. first two letters of genus and first two letters of species, sometimes followed by a number                                                    \n",
    "| Genus_species               | Genus and species of tree                                      \n",
    "| DBH_cm                      | diameter and breast height rounded to nearest 0.1\n",
    "| HT_m                        | pre-fire tree height rounded to nearest 0.01 m\n",
    "| CR_pre                      | pre-fire live crown ratio. crown length divided by tree height\n",
    "| CR_post                     | post-fire live crown ratio. crown length divided by tree height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d355a0",
   "metadata": {},
   "source": [
    "## Step 2: Fetch  data\n",
    "Read in the data set and filter to retain only the variables of interest.  Then check for incomplete observations and remove any rows containing NaNs.  How many observations does that leave us with? **Print your answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac926dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations left after removing NAs: 36509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1219957/2769784280.py:2: DtypeWarning: Columns (4,5,6,7,10,62,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trees_dat = pd.read_csv('/courses/EDS232/Data/FTM_trees.csv')[['YrFireName', 'Species', 'Times_burned', 'yr1status', 'Genus_species', 'DBH_cm', 'HT_m', 'CR_pre', 'CR_post']].dropna()\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "trees_dat = pd.read_csv('/courses/EDS232/Data/FTM_trees.csv')[['YrFireName', 'Species', 'Times_burned', 'yr1status', 'Genus_species', 'DBH_cm', 'HT_m', 'CR_pre', 'CR_post']].dropna()\n",
    "print(f\"Observations left after removing NAs: {trees_dat.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf806bf",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing\n",
    "1. We recode categorical predictors to zero-based integer form because most machine learning models, including logistic regression, cannot work directly with categorical data represented as strings or labels. Instead, models require numerical input. Let's do that here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e41fb79-ad31-4162-ac76-887461bb4160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in ['YrFireName', 'Species', 'Genus_species']:\n",
    "    trees_dat[f\"{col}_cat\"] = trees_dat[col].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc4673-26dc-4c09-8c9a-0f2f97abe16f",
   "metadata": {},
   "source": [
    "2. Then we'll split into training and test data and scale for coefficient interpretability.  Recall that we use the training features to calculate our scaling parameters (mean and standard deviation) and apply the scaling to those training features (`scaler.fit_transform`) and then apply the scaling to the features in the test data as well (`scaler.transform`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54b2f9d2-f414-4bf2-b0a3-51d55f3d997a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = trees_dat.drop(['Species', 'Genus_species', 'YrFireName', 'yr1status'], axis=1)\n",
    "y = trees_dat['yr1status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055eca1-9c22-4266-95a0-710b43be5a8e",
   "metadata": {},
   "source": [
    "3. How many training/test observations do we have? Print your answer in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdb4803d-8680-4ede-b790-3579f4a485e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set observations:  25556\n",
      "Testing set observations: 10953\n"
     ]
    }
   ],
   "source": [
    "train_obs = len(X_train_scaled)\n",
    "test_obs = len(X_test_scaled)\n",
    "\n",
    "# Verify the training and testing set size\n",
    "print(\"Training set observations: \",train_obs )\n",
    "print(\"Testing set observations:\",test_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8857c",
   "metadata": {},
   "source": [
    "## Step 4: Train a Logistical Model\n",
    "Create a classifier using `LogisticRegression()` and fit it on the training data.  Then assess the model's accuracy on the training set by making predictions on the training data.  Calculate and **print** the accuracy of your model on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "578b2ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.054938174988261076\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "print(f\"Training Accuracy: {mean_squared_error(y_train, y_train_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d86616",
   "metadata": {},
   "source": [
    "## Step 5: Test Set Predictions and Model Evaluation\n",
    "Now let's take our trained logistic classifier and make predictions on the test set. Calculate the accuracy and confusion matrix. Then use `sns.heatmap` for improved confusion matrix visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4e4d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "...\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: \")\n",
    "\n",
    "\n",
    "#Plot confusion matrix\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cdbbb",
   "metadata": {},
   "source": [
    "## Step 6: Logistic Classifier Evaluation\n",
    "How did your model perform on the unseen data? \n",
    "Does your model perform differently on observations of trees that survived vs trees that died?\n",
    "Is there a class imbalance in this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c651ef7",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c7e36",
   "metadata": {},
   "source": [
    "## Step 7: What about a Dummy?\n",
    "What do you think would happen if we built a model that always predicts the majority class (dead trees)? How would its accuracy compare to your logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ba576",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854360d",
   "metadata": {},
   "source": [
    "Let's go ahead and do it: use `DummyClassifier()` with the appropriate value for the 'strategy' parameter to train a majority classifier.  Then calculate this model's accuracy on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe5b4015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Accuracy: \n",
      "\n",
      "Dummy Confusion Matrix:\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "\n",
    "# Print accuracy and confusion matrix results\n",
    "print(f\"Dummy Accuracy: \")\n",
    "print(\"\\nDummy Confusion Matrix:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3445d23",
   "metadata": {},
   "source": [
    "# Step 8: ROCs and AUCs\n",
    "Our two models have similar accuracy, but is that all there is to this story?  Let's dig a little deeper on the comparison of our logistic and dummy classifiers by examining the associated receiver-operator characteristic (ROC) curves. Calculate the area under the curve (AUC) for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef8515b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic AUC: \n"
     ]
    }
   ],
   "source": [
    "# Logistic classifier AUC\n",
    "...\n",
    "print(f\"Logistic AUC: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5180e8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy AUC: \n"
     ]
    }
   ],
   "source": [
    "# Dummy classifier AUC\n",
    "...\n",
    "print(f\"Dummy AUC: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd252f",
   "metadata": {},
   "source": [
    "# Step 9: Plot dummy and logistic model ROC curves\n",
    "Now using the outputs from `roc_curve()`, plot the ROC curves for both models on the same plot.  Make sure to use appropriate labels in the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7fe29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec104e80",
   "metadata": {},
   "source": [
    "How do the two models compare on AUC?  What are the implications for evaluating classifiers based on accuracy of their predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab1a30",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1767d77",
   "metadata": {},
   "source": [
    "# Step 10: Final interpretation\n",
    "\n",
    "Identifying the most important features in a model can guide decision-making. For instance, in our dataset, highly important features might indicate key factors affecting tree survival after a fire. We will calculate the feature importance by examining the coefficients of our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a97e03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'importance_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Print the sorted feature importance\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimportance_df\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'importance_df' is not defined"
     ]
    }
   ],
   "source": [
    "...\n",
    "\n",
    "# Print the sorted feature importance\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9db5d",
   "metadata": {},
   "source": [
    "Which are the most important features in our model (reference the metadata to help answer this)? Can you think of any implications for forest management or conservation strategy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42e56c",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
